# from sgnlp.models.sentic_gcn import ()

config = .from_pretrained(
    # google storage .json file
)

model = .from_pretrained(
    # google storage, .bin file
    , config=config
)

# Download tokenizer files